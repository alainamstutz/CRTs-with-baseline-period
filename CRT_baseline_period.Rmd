---
title: "CRT_baseline_period"
author: "A.Amstutz"
date: "2025-03-15"
output:
  html_document:
    keep_md: yes
    toc: yes
    toc_float: yes
    code_folding: hide
  pdf_document:
    toc: yes
---

## Parallel CRT with baseline period
1. "A common enhancement of a simple parallel CRT is to add an assessment of participants‚Äô outcomes in a baseline period (before randomisation). Even if different participants are assessed at baseline and follow-up [i.e. cross-sectional sampling], the fact that they are sampled from the same cluster allows some control for cluster differences." -> https://www.bmj.com/content/360/bmj.k1121
2. This is illustratively shown in the sample size calculator: https://clusterrcts.shinyapps.io/rshinyapp/ (switch between "Parallel" and "Parallel with baseline measure") -> can yield a substantial increase in power! See last chapter below.

Let's explore this further
* The rationale: The more variability there is in the outcome across clusters, the more difficult to identify the effect.
* On the example of an individual RCT: "if we are interested in measuring the impact of an intervention on the quality of life (QOL) across a diverse range of patients, the measurement (which typically ranges from 0 to 1) might vary considerably from person to person, regardless of the intervention. If the intervention has a real but moderate effect of, say, 0.1 points, it could easily get lost if the standard deviation is considerably larger, say 0.25."
* If we collect baseline QOL scores and can ‚Äúcontrol‚Äù for those measurements in some way (by conducting a repeated measures analysis, using ANCOVA, or assessing the difference itself as an outcome), we might be able to reduce the variability and have better chance to pick up the effect. 

Literature:
* https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.5352 
* Hooper Richard et al. Sample size calculation for stepped wedge and other longitudinal cluster randomised trials. Statistics in Medicine. 2016: https://onlinelibrary.wiley.com/doi/10.1002/sim.7028 and 
* Leyrat Cl√©mence et al. Practical considerations for sample size calculation for cluster randomized trials. Journal of Epidemiology and Population Health. 2024: https://www.sciencedirect.com/science/article/pii/S2950433324000090
* Based on: https://www.bmj.com/content/360/bmj.k1121.long

## There are various ways to do it:
1. Analysis of covariance (ANCOVA): Aggregate outcomes at baseline, and adjusts each individual participant at follow-up for the baseline cluster mean
2. Constrained baseline analysis: Treat outcomes collected at baseline and follow-up as longitudinal, and to use a repeated measures analysis to estimate the effect of the intervention being switched on in one of the randomised groups on the second of these occasions, see design matrix in https://clusterrcts.shinyapps.io/rshinyapp/. Unlike a difference of differences analysis, it assumes that there is no systematic difference between the groups at baseline.

## Simulation
### First, start with a simple individual randomized trial
```{r message=FALSE, warning=FALSE}
RNGkind("L'Ecuyer-CMRG")
set.seed(19287)
library(simstudy)
library(ggplot2)
library(lmerTest)
library(parallel)
library(data.table)
library(pwr)
library(gtsummary)
library(paletteer)
library(magrittr)
```

In this examples the overall variance isùúé= 64 (regardless of treatment group) and thus here, the individual-levelùúé= 64 is the only source of variation. The overall effect size ùõø, which is the difference in average QoL scores across treatment groups, is assumed to be 2.4, a standardized effect size 2.4/8=0.3, i.e., the treatment effect of 2.4 is about 0.3 standard deviations large (Cohen's d), which is a moderate effect size in typical clinical trials.
Let's calculate the sample size for a two-sample t-test (2 groups, independent, only 1 measurement at the end) based on the effect size (Cohen's d) and a power of 80%.
```{r}
pwr.t.test(d = 0.3, power = 0.80)
```
We will need 350 participants (175 in each arm) to achieve a power of 80%.

#### Let's generate the data
```{r}
simple_rct <- function(N) {
  
  # data definition for outcome
  
  defS <- defData(varname = "rx", formula = "1;1", dist = "trtAssign") # treatment variable, 1:1 allocation, 50% prob to be in a or b
  defS <- defData(defS, varname = "y", formula = "2.4*rx", variance = 64, dist = "normal") # outcome, continuous, 
  # If rx = 1 (treatment group), the outcome will be 2.4*1 = 2.4.
  # If rx = 0 (control group), the outcome will be 2.4*0 = 0.
  # variance: spread or variability in the scores within each group.
  # dist = "normal" indicates that the outcome variable (y) will follow a normal distribution.
  # The outcome variable has a mean of 2.4 for the treatment group and 0 for the control group, with a variance of 64.
  dd <- genData(N, defS)
  
  dd[]
}

dd <- simple_rct(350) # simulate the trial with 350 participants

ggplot(dd, aes(x = factor(rx), y = y, fill = factor(rx))) + 
  # Violin plot
  geom_violin(trim = FALSE) + 
  # Add the individual data points
  geom_jitter(width = 0.15, size = 1, alpha = 0.6, color = "black") +
  # Add a point estimate (median)
  stat_summary(fun = "median", geom = "point", shape = 18, size = 3, color = "red") +
  # Boxplot to show interquartile range (optional, can be removed if not needed)
  geom_boxplot(width = 0.1, alpha = 0.5, outlier.shape = NA, color = "black") +
  labs(x = "Treatment Group (rx)", y = "Outcome (y)") +
  scale_fill_manual(values = c("skyblue", "salmon")) + 
  theme_minimal() +
  theme(legend.title = element_blank()) +
  ggtitle("Violin Plots with Point Estimate and Individual Data Points")

```

#### Let's estimate the effect size
A simple linear regression model will do
```{r}
fit1 <- lm(y ~ rx, data = dd)
tbl_regression(fit1) %>% 
  modify_footnote(ci ~ NA, abbreviation = TRUE)
```

#### Let's confirm the power
We can confirm the power by repeatedly generating data sets and fitting models, recording the p-values for each replication.
```{r}
replicate <- function() {
  dd <- simple_rct(350)
  fit1 <- lm(y ~  rx, data = dd)
  coef(summary(fit1))["rx", "Pr(>|t|)"]
}

p_values <- mclapply(1:1000, function(x) replicate(), mc.cores = 4) # mclapply() is a parallelized version of the lapply() function that applies the replicate() function 1000 times. mc.cores = 4 means the code will use 4 cores for parallel computation, which speeds up the process by running multiple replications simultaneously.

# Estimated power based on 1000 replications.
# Convert the list of p-values into a vector and calculates the proportion of replications where the p-value is less than 0.05
mean(unlist(p_values) < 0.05)
```

### Second, now move to a cluster randomized trial, but same context
Parallel cluster randomized trial:
ùëåùëñùëó=ùõº+ùõøùëçùëó+ùëêùëó+ùë†ùëñ

where ùëåùëñùëó is a continuous outcome for participant ùëñ in site ùëó. ùëçùëó is the treatment indicator for site ùëó. Again, ùõø is the treatment effect. ùëêùëó‚àºùëÅ(0,ùúé^2ùëê) is a site level effect, and ùë†ùëñ‚àºùëÅ(0,ùúé^2ùë†) is the participant level effect. The correlation of any two participants in a cluster is ùúå (the ICC):

ùúå=ùúé^2ùëê/ (ùúé^2ùëê+ùúé^2ùë†)

This tells us how correlated participants are within the same cluster.
If œÅ is close to 0, most of the variability is at the individual level.
If œÅ is close to 1, most of the variability is at the site level.

If we have a pre-specified number (ùëõ) of participants at each site, we can estimate the sample size required in the CRT applying a design effect 1+(ùëõ‚àí1)ùúå to the sample size of an RCT that has the same overall variance.
We know the overall variance (ùúé^2) is 64 and we assume/know the ICC/p is 0.15. That brings us to (using the ICC formula above)

œÉ^2 c = 9.6 (site-level variance)
œÉ^2 s = 54.4 (individual-level variance)
ICC (œÅ) = 0.15: 15% of the total variability in the outcome is due to differences between sites, while 85% is due to individual differences within sites.

Since individuals in the same cluster are correlated, we need to adjust the sample size using the design effect.
Design Effect = 1+(n‚àí1)œÅ; where, n=30 (number of individuals per site), œÅ = 0.15
=> Design effect = 5.35
=> New Total Sample Size = 5.35 √ó 350 = 1872
Since each site includes 30 participants, the number of required sites is: 62.4 => 64

#### Let's generate the data
```{r}
simple_crt <- function(nsites, n) {
  # treatment assignment, again, 1:1, 50% prob to be in each group
  defC <- defData(varname = "rx", formula = "1;1", dist = "trtAssign")
  # Define Cluster-Level Data (defC)
  # c (Random Site Effect from Normal Distribution)
  # This represents site-level variation. It follows a normal distribution
  # variance = 9.6 is the site-level variance (see above)
  defC <- defData(defC, varname = "c", formula = "0", variance = 9.6, dist = "normal")  
  # Define Individual-Level Outcome (defS)
  # c: Site-level effect (previously defined).
  # 2.4 * rx: Treatment effect for clusters assigned to intervention, see above
  # s_i \sim N(0, 54.4): Individual-level noise, with variance 54.4.
  defS <- defDataAdd(varname="y", formula="c + 2.4*rx", variance = 54.4, dist="normal")

# site/cluster level data
  # Generates nsites rows (one per cluster)
  # Each row includes: rx (treatment assignment for the site) and c (site-specific random effect).
  dc <- genData(nsites, defC, id = "site")

# individual level data
  # Creates individual-level data by assigning n individuals to each site.
  # Adds outcome (y) based on c, rx, and individual-level variance.
  dd <- genCluster(dc, "site", n, "id")
  dd <- addColumns(defS, dd)
  
  dd[]
}
# generating data for 20 sites, each with 50 individuals.
dd <- simple_crt(20, 50)

# Create violin plot with sites on x-axis and colors for treatment/control
ggplot(dd, aes(x = factor(site), y = y, fill = factor(rx))) +
  geom_violin(trim = FALSE, alpha = 0.5) +  # Violin plot with transparency
  geom_boxplot(width = 0.2, outlier.shape = NA, color = "black") +  # Boxplot for central tendency
  geom_jitter(shape = 16, position = position_jitter(0.2), alpha = 0.4) +  # Scatter individual points
  scale_fill_manual(values = c("blue", "red"), labels = c("Control", "Treatment")) +
  labs(x = "Site (Cluster)", y = "Outcome (y)", title = "Outcome Distribution by Site") +
  theme_minimal() +
  theme(legend.title = element_blank(), axis.text.x = element_text(angle = 90, hjust = 1))
```

#### Let's estimate the effect size
A mixed effects model is used to estimate the effect size.
```{r}
dd <- simple_crt(200,100)

fit2 <- lmer(y ~  rx + (1|site), data = dd)
tbl_regression(fit2, tidy_fun = broom.mixed::tidy)  %>% 
  modify_footnote(ci ~ NA, abbreviation = TRUE)
```

#### Let's confirm the power
Confirm power and go back to the initial assumption of 64 sites with 30 participants per site, which is a massive increase from total sample size 350 (individual RCT) to 1920 in a simple CRT
```{r}
replicate <- function() {
  dd <- simple_crt(64, 30)
  fit2 <- lmer(y ~  rx + (1|site), data = dd)
  
  coef(summary(fit2))["rx", "Pr(>|t|)"]
}

p_values <- mclapply(1:1000, function(x) replicate(), mc.cores = 4)

mean(unlist(p_values) < 0.05)

# Run the power analysis simulation
p_values <- unlist(p_values)  # Convert list to vector

# Create histogram
ggplot(data.frame(p_values), aes(x = p_values)) +
  geom_histogram(binwidth = 0.05, fill = "blue", color = "black", alpha = 0.7) +
  geom_vline(xintercept = 0.05, linetype = "dashed", color = "red", linewidth = 1) +
  labs(title = "Distribution of p-values from 1000 Simulations",
       x = "p-value",
       y = "Frequency") +
  theme_minimal()

```

### Third, we move to a CRT with baseline period
The baseline and follow-up measurements can be collected from the same participants (cohort design) or different participants (cross-sectional design), though the impact on the design effect depends on what approach is taken.
The key idea is to measure the same outcome at two different time points to reduce variance and improve statistical power.

ùëåùëñùëóùëò = ùõº0 + ùõº1ùëò + ùõø0ùëçùëó + ùõø1ùëòùëçùëó + ùëêùëó + ùëêùëùùëóùëò + ùë†ùëñùëó + ùë†ùëùùëñùëóùëò

where ùëåùëñùëóùëò is a continuous outcome measure for individual ùëñ in site ùëó and measurement ùëò‚àà{0,1}. ùëò=0 for baseline measurement, and ùëò=1 for the follow-up. 
ùëçùëó is the treatment status of cluster ùëó, ùëçùëó‚àà{0,1}. 
ùõº0 is the mean outcome at baseline for participants in the control cluster. Baseline mean outcome in control clusters.
ùõº1 is the change from baseline to follow-up in the control arm. Change over time in the control arm (i.e., how much the outcome changes naturally without intervention).
ùõø0 is the difference at baseline between control and treatment arms (we would expect this to be 0 in a randomized trial)  
ùõø1 is the difference in the change from baseline to follow-up between the two arms. In a randomized trial, since ùõø0 should be close to 0, ùõø1 is the treatment effect. Treatment effect, i.e., the difference in change from baseline to follow-up between treatment and control arms.

The model has cluster-specific and individual-specific random effects. 
For both, there can be time-invariant effects and time-varying effects.
Cluster-level effects (between-site variation):
ùëêùëó‚àºùëÅ(0,ùúé2ùëê) are time invariant site-specific effects. Intrinsic differences between clusters.
ùëêùëùùëóùëò ‚àºùëÅ(0,ùúé2ùëêùëù) are the site-specific period (time varying) effects. Changes over time within a site.
Individual-level effects (within-site variation):
ùë†ùëñùëó‚àºùëÅ(0,ùúé2ùë†) are time invariant individual-level effects, stable individual characteristics.
ùë†ùëùùëñùëóùëò‚àºùëÅ(0,ùúé2ùë†ùëù) are the individual-level period (time varying) effects, measurement error or individual change over time.

Why Does This Help Reduce Sample Size?
1. Since each individual (or site) has two measurements, we can control for their baseline score when estimating the treatment effect.
2. This reduces residual variance, leading to a lower design effect and a smaller required sample size compared to a standard CRT.
3. The benefit depends on the intra-cluster correlation (ICC) and how much baseline values predict follow-up values.

#### Let's generate the data
```{r}
# Parameters:

# effect: The treatment effect to be used for the formula in the outcome variable.
# nsites: The number of sites (clusters) in the study.
# n: The number of participants at each site.
# s_c, s_cp, s_s, s_sp: These represent the variances of the respective random effects:
#  s_c: Variance of cluster-level (site-level) time-invariant random effects.
#  s_cp: Variance of cluster-level (site-level) time-varying random effects (due to different periods).
#  s_s: Variance of participant-level time-invariant random effects.
#  s_sp: Variance of participant-level time-varying random effects (due to periods).

crt_base <- function(effect, nsites, n, s_c, s_cp, s_s, s_sp) {
  # Variable c = cluster level, with variance s_c. It represents the time-invariant random effects at the cluster level.
  defC <- defData(varname = "c", formula = 0, variance = "..s_c")
  defC <- defData(defC, varname = "rx", formula = "1;1", dist = "trtAssign")
  # Cluster-Level Time-Varying Effects (defCP)
  # This defines time-varying cluster-level random effects c.p with variance s_cp. This effect captures the change over time within clusters, for example, the different responses between baseline and follow-up at each site.
  defCP <- defDataAdd(varname = "c.p", formula = 0, variance = "..s_cp")
  # This defines the individual-level random effects s with variance s_s. This represents individual individual variability that is constant across time.
  defS <- defDataAdd(varname = "s", formula = 0, variance = "..s_s")
  # The treatment effect (effect) for the interaction between the treatment indicator (rx) and the period (period), which gives the treatment effect over time.
  defSP <- defDataAdd(varname = "y",
    formula = "..effect * rx * period + c + c.p + s", 
    variance ="..s_sp")
  
  dc <- genData(nsites, defC, id = "site")
  
  # Add Periods to Cluster Data (dcp)
  # This adds two periods (baseline and follow-up) to each cluster and adds the time-varying random effects (c.p).
  dcp <- addPeriods(dc, 2, "site")
  dcp <- addColumns(defCP, dcp)
  dcp <- dcp[, .(site, period, c.p, timeID)]
  
  # Generate Individual-Level Data (ds)
  ds <- genCluster(dc, "site", n, "id")
  ds <- addColumns(defS, ds)
  
  # Add Periods to Individual-Level Data (dsp)
  # This adds two periods (baseline and follow-up) for each individual, creating the observational ID obsID.
  dsp <- addPeriods(ds, 2)
  setnames(dsp, "timeID", "obsID")
  
  setkey(dsp, site, period)
  setkey(dcp, site, period)
  
  # Merge Cluster-Level and Individual-Level Data (dd)
  dd <- merge(dsp, dcp)
  dd <- addColumns(defSP, dd)
  setkey(dd, site, id, period)
  
  dd[]
}

```

Design effect

In their paper, Teerenstra et al develop a design effect that takes into account the baseline measurement.

The correlation of two participant measurements in the same cluster and same time period is the ICC or ùúå, and is:

ùúå = (ùúé2ùëê + ùúé2ùëêùëù) / (ùúé2ùëê + ùúé2ùëêùëù + ùúé2ùë† + ùúé2ùë†ùëù)

In order to estimate the design effect, we need two more correlations. 
First, the correlation between baseline and follow-up random effects at the cluster level:

ùúåùëê = ùúé2ùëê/ (ùúé2ùëê + ùúé2ùëêùëù)

Second, the correlation between baseline and follow-up random effects at the individual level:

ùúåùë† = ùúé2ùë†/ (ùúé2ùë†+ùúé2ùë†ùëù)

A value ùëü is used to estimate the design effect, and is defined as:

ùëü= (ùëõùúåùúåùëê + (1‚àíùúå)ùúåùë†) / (1 + (ùëõ‚àí1)ùúå)

If we are able to collect baseline measurements and our focus is on estimating ùõø1 from the model, the design effect is slightly modified from before:

(1+(ùëõ‚àí1)ùúå) * (2(1‚àíùëü))

-> Basically, adding the second part with rho. r: The correlation factor, which is a weighted combination of the cluster-level and individual-level correlations.
The first part of the formula is similar to the design effect formula used when baseline data isn't available. It adjusts for the clustering of individuals within sites (clusters), accounting for the intra-cluster correlation.
The second part of the formula adjusts for the reduction in variance due to the inclusion of baseline measurements in the analysis. The value of r reflects how strongly the baseline and follow-up measurements correlate at both the cluster and individual levels.
If the correlation between baseline and follow-up measurements is strong (i.e., high ps and high pc), this part of the formula will be small, implying a lower design effect (and thus a lower required sample size).

By collecting baseline measurements, the baseline-to-follow-up correlation reduces the variability in the outcome variable, which allows for more precise estimates of the treatment effect and smaller sample size requirements. Specifically, reducing noise and allowing you to detect smaller treatment effects with the same sample size.
By using the correlation between baseline and follow-up data, you can "shrink" the variability and make the study more efficient. This is crucial if the cost or effort of data collection is high, as it helps you achieve the same statistical power with a smaller sample.


#### Cross-section cohort design
We may not be able to collect two measurements for each participants at a site, but if we can collect measurements on two different cohorts, one at baseline before the intervention is implemented, and one cohort in a second period (either after the intervention has been implemented or not, depending on the randomization assignment of the cluster), we might be able to reduce the number of clusters.

In this case, ùúé2ùë†= 0 and ùúåùë†= 0, so the general model reduces to:

ùëåùëñùëóùëò = ùõº0 + ùõº1ùëò + ùõø0ùëçùëó + ùõø1ùëòùëçùëó + ùëêùëó + ùëêùëùùëóùëò + ùë†ùëùùëñùëóùëò

So, we can drop ùë†ùëñùëó because there is no individual-level correlation (independent participants)

The parameters for this simulation are 
ùõø1= 2.4 (treatment effect, see above)
ùúé2ùëê= 6.8 (Cluster-level variance)
ùúé2ùëêùëù= 2.8 (Cluster-level period variance)
ùúé2ùë†ùëù= 54.4 (Individual-level period variance) 
Total variance:ùúé2ùëê + ùúé2ùëêùëù + ùúé2ùë†ùëù = 6.8 + 2.8 + 54.4 = 64, as used previously.

```{r}
dd <- crt_base(effect = 2.4, nsites = 20, n = 30, s_c = 6.8, s_cp = 2.8, s_s = 0, s_sp = 54.4)

# Create a new column for period names (baseline and follow-up)
dd[, period_label := ifelse(period == 0, "Baseline", "Follow-up")]

# Create a violin plot, faceted by site
ggplot(dd, aes(x = period_label, y = y, fill = factor(rx))) + 
  geom_violin(trim = FALSE, alpha = 0.1) +  # Make the violin plot transparent
  geom_jitter(aes(color = factor(rx)), width = 0.1, alpha = 0.5) +  # Add individual data points
  geom_boxplot(width = 0.1, color = "black", alpha = 0.3, outlier.shape = NA) +  # Add boxplots
  facet_wrap(~site, ncol = 5) +  # 5 columns for 20 sites
  scale_fill_manual(values = c("blue", "red"), labels = c("Control", "Intervention")) +
  scale_color_manual(values = c("blue", "red")) +
  labs(title = "Violin Plot with Data Points and Boxplots by Site and Treatment Group", 
       x = "Measurement Time", y = "Outcome Value") +
  theme_minimal() + 
  theme(legend.position = "bottom", 
        strip.text = element_text(size = 8), 
        axis.text.x = element_text(angle = 45, hjust = 1))  # Adjust text angles for clarity

```

#### Let's estimate the effect size
To estimate the effect size we fit a mixed effect model with cluster-specific effects only (both time invariant and time varying).
Treatment effect under "period*rx" !
Translating the Formula:
Fixed Effects:
Fixed effect for ùõº1ùëò: This is represented by period in the model, which captures the difference between baseline and follow-up.
Fixed effect for treatment group (rx) ùõø0ùëçùëó : This is represented by rx and captures whether the site received treatment or control.
Interaction of time and treatment (period * rx) ùõø1ùëòùëçùëó : This interaction term captures how the treatment effect differs between baseline and follow-up.
Random Effects:
(1 | site): ùëêùëó : A random intercept for each site. This accounts for the variability between sites but assumes the variability is constant across time (since it's not tied to the period).
(1 | timeID:site):ùëêùëùùëóùëò: A random intercept for each site in each time period (baseline and follow-up). This accounts for the site-specific changes over time‚Äîit captures how variability between sites changes from baseline to follow-up.
s pij is not included in your current model for the cross-sectional design because you are assuming independence between individuals at baseline and follow-up.
```{r}
dd <- crt_base(effect = 2.4, nsites = 200, n = 100, s_c=6.8, s_cp=2.8, s_s=0, s_sp=54.4)

fit3 <- lmer(y ~ period * rx + (1|timeID:site) + (1 | site), data = dd)
tbl_regression(fit3, tidy_fun = broom.mixed::tidy)  %>% 
  modify_footnote(ci ~ NA, abbreviation = TRUE)
```

#### Let's update the Design Effect
```{r}
# Based on the variance assumptions, we can update our design effect:
s_c <- 6.8
s_cp <- 2.8
s_s <- 0
s_sp <- 54.4

rho <- (s_c + s_cp)/(s_c + s_cp + s_s + s_sp)
rho_c <- s_c/(s_c + s_cp)
rho_s <- s_s/(s_s + s_sp)

n <- 30

r <- (n * rho * rho_c + (1-rho) * rho_s) / (1 + (n-1) * rho)

# The design effect for the CRT without any baseline measurement was 5.35. With the two-cohort design, the design effect is reduced slightly:
(des_effect <- (1 + (n - 1) * rho) * 2 * (1 - r))
## [1] 4.3

# and thus leaves us with:
des_effect * 350 / n
## [1] 50

# The desired number of sites is over 50, so rounding up to the next even number gives us 52
```

#### Let's confirm the power
After calculating the design effect, we run a simulation to confirm the statistical power based on the specified number of sites (52) and participants per site (30). The goal is to check whether the p-value for the treatment effect (period*rx) is statistically significant in at least 80% of simulations.
```{r}
replicate <- function() {
  dd <- crt_base(2.4, 52, 30, s_c = 6.8, s_cp = 2.8, s_s = 0, s_sp = 54.4)
  fit3 <- lmer(y ~ period * rx + (1|timeID:site) + (1 | site), data = dd)
  
  coef(summary(fit3))["period:rx", "Pr(>|t|)"]
}

p_values <- mclapply(1:1000, function(x) replicate(), mc.cores = 4)

mean(unlist(p_values) < 0.05)

```

#### Closed cohort design
We can reduce the number of clusters further if instead of measuring one cohort prior to the intervention and another after the intervention, we measure a single cohort twice - once at baseline and once at follow-up. Now we use the full model that decomposes the participant level variance into a time invariant effect (ùëêùëó) and a time varying effect (ùëêùëùùëóùëò):

ùëåùëñùëóùëò = ùõº0 + ùõº1ùëò + ùõø0ùëçùëó + ùõø1ùëòùëçùëó + ùëêùëó + ùëêùëùùëóùëò + ùë†ùëñùëó + ùë†ùëùùëñùëóùëò

#### Let's generate the data
The parameters for this simulation are 
ùõø1 = 2.4 (treatment effect, see above)
ùúé2ùëê = 6.8 (Cluster-level variance)
ùúé2ùëêùëù = 2.8 (Cluster-level period variance)
ùúéùë† = 38 (Individual-level variance) 
ùúé2ùë†ùëù = 16.4 (Individual-level period variance) 
Total variance = 64, as used previously.
```{r}
dd <- crt_base(effect=2.4, nsites=20, n=30, s_c=6.8, s_cp=2.8, s_s=38, s_sp=16.4)

# Visualizing the data (2 time points: baseline and follow-up)
ggplot(dd, aes(x = period, y = y, group = id, color = as.factor(rx))) +
  geom_line() +
  geom_point(aes(shape = as.factor(rx)), size = 3) +
  facet_wrap(~site, ncol = 5) +
  scale_color_manual(values = c("blue", "red")) +
  labs(title = "Repeated Measurements: Outcome by Site and Time",
       x = "Time Period (0 = Baseline, 1 = Follow-up)",
       y = "Outcome (y)",
       color = "Treatment",
       shape = "Treatment") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

#### Let's estimate the effect size
The mixed effect model includes cluster-specific effects only (both time invariant and time varying), as well as subject level effects. 
```{r}
dd <- crt_base(effect = 2.4, nsites = 200, n = 100, 
  s_c = 6.8, s_cp = 2.8, s_s = 38, s_sp = 16.4)

fit4 <- lmer(y ~ period*rx + (1 | id:site) + (1|timeID:site) + (1 | site), data = dd)
tbl_regression(fit4, tidy_fun = broom.mixed::tidy)  %>% 
  modify_footnote(ci ~ NA, abbreviation = TRUE)
```

#### Let's update the Design Effect
```{r}
# Based on the variance assumptions, we can update our design effect a second time:
s_c <- 6.8
s_cp <- 2.8
s_s <- 38
s_sp <- 16.4

rho <- (s_c + s_cp)/(s_c + s_cp + s_s + s_sp)
rho_c <- s_c/(s_c + s_cp)
rho_s <- s_s/(s_s + s_sp)

n <- 30

r <- (n * rho * rho_c + (1-rho) * rho_s) / (1 + (n-1) * rho)

# And again, the design effect (and sample size requirement) is reduced:
(des_effect <- (1 + (n - 1) * rho) * 2 * (1 - r))
## [1] 3.1
des_effect * 350 / n
## [1] 37

# The desired number of sites is over 36, so I will round up to 38
```

#### Let's confirm the power
After calculating the design effect, we run a simulation to confirm the statistical power based on the specified number of sites (52) and participants per site (30). The goal is to check whether the p-value for the treatment effect (period*rx) is statistically significant in at least 80% of simulations.
```{r}
replicate <- function() {
  dd <- crt_base(2.4, 38, 30, s_c = 6.8, s_cp = 2.8, s_s = 38, s_sp = 16.4)
  fit4 <-  lmer(y ~ period*rx + (1 | id:site) + (1|timeID:site) + (1 | site), data = dd)
  
  coef(summary(fit4))["period:rx", "Pr(>|t|)"]
}

p_values <- mclapply(1:50, function(x) replicate(), mc.cores = 4) # increase once more computational capacity

mean(unlist(p_values) < 0.05)
## [1] 0.79
```


